# Seefast Backend

AI-powered data visualization agent backend using LangGraph and FastAPI.

## Features

- ğŸ¤– **LangGraph Agent** - Stateful AI agent with tool-calling
- ğŸ” **Semantic Search** - ChromaDB for API endpoint discovery
- ğŸ’¾ **Caching** - Redis with in-memory fallback
- ğŸ’¬ **Conversation Memory** - Context across turns
- ğŸ“Š **Auto-formatting** - Raw API data â†’ Widgets

## Tech Stack

- **FastAPI** - API framework
- **LangGraph** - Agent orchestration
- **LangChain OpenAI** - LLM integration
- **ChromaDB** - Vector database
- **Redis** - Caching
- **Sentence Transformers** - Embeddings

## Quick Start

```bash
# 1. Create virtual environment
python -m venv venv
source venv/bin/activate  # or `venv\Scripts\activate` on Windows

# 2. Install dependencies
pip install -r requirements.txt

# 3. Configure environment
cp .env.example .env
# Edit .env and add your OPENAI_API_KEY

# 4. Start Redis (optional)
docker run -d -p 6379:6379 redis:alpine

# 5. Run server
uvicorn app.main:app --reload
```

Server runs at http://localhost:8000

## Project Structure

```
app/
â”œâ”€â”€ main.py              # FastAPI entry + startup
â”œâ”€â”€ config.py            # Settings (env vars)
â”œâ”€â”€ api/
â”‚   â””â”€â”€ routes.py        # API endpoints
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ core.py          # Agent entry point
â”‚   â”œâ”€â”€ graph.py         # LangGraph definition
â”‚   â”œâ”€â”€ tools.py         # Agent tools
â”‚   â”œâ”€â”€ memory.py        # Conversation memory
â”‚   â”œâ”€â”€ state.py         # State definition
â”‚   â””â”€â”€ prompts.py       # System prompts
â”œâ”€â”€ adapters/
â”‚   â””â”€â”€ swagger_parser.py # OpenAPI parser
â”œâ”€â”€ registry/
â”‚   â””â”€â”€ endpoint_registry.py # ChromaDB endpoint store
â””â”€â”€ services/
    â””â”€â”€ cache.py         # Redis cache
```

## API Endpoints

| Method | Path | Description |
|--------|------|-------------|
| POST | `/api/query` | Send query to agent |
| GET | `/api/sessions/{id}` | Get session info |
| GET | `/health` | Health check |
| GET | `/docs` | OpenAPI docs |

## Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `OPENAI_API_KEY` | OpenAI API key | Required |
| `OPENAI_MODEL` | Model to use | `gpt-4o` |
| `REDIS_URL` | Redis connection | `redis://localhost:6379` |
| `SWAGGER_URL` | API spec URL | Petstore |

## How It Works

```
User Query
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Load Context   â”‚ â† Conversation memory
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LangGraph      â”‚
â”‚  Agent Loop:    â”‚
â”‚  â€¢ search_endpoints
â”‚  â€¢ get_endpoint_schema
â”‚  â€¢ call_api
â”‚  â€¢ format_for_widget
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Format Output  â”‚ â†’ Widgets JSON
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
Response { message, widgets[] }
```

## License

MIT
